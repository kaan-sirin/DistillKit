# This file was autogenerated by uv via the following command:
#    uv pip compile pyproject.toml -o requirements.txt
absl-py==2.2.2
    # via rouge-score
accelerate==1.6.0
    # via
    #   distillkit (pyproject.toml)
    #   lm-eval
    #   peft
    #   trl
aiohappyeyeballs==2.6.1
    # via aiohttp
aiohttp==3.11.18
    # via
    #   datasets
    #   fsspec
aiosignal==1.3.2
    # via aiohttp
annotated-types==0.7.0
    # via pydantic
anyio==4.9.0
    # via
    #   httpx
    #   openai
attrs==25.3.0
    # via
    #   aiohttp
    #   jsonlines
bert-score==0.3.13
    # via distillkit (pyproject.toml)
bitsandbytes==0.45.5
    # via distillkit (pyproject.toml)
certifi==2025.1.31
    # via
    #   httpcore
    #   httpx
    #   requests
    #   sentry-sdk
chardet==5.2.0
    # via mbstrdecoder
charset-normalizer==3.4.1
    # via requests
click==8.1.8
    # via
    #   nltk
    #   wandb
colorama==0.4.6
    # via
    #   sacrebleu
    #   tqdm-multiprocess
contourpy==1.3.2
    # via matplotlib
cycler==0.12.1
    # via matplotlib
dataproperty==1.1.0
    # via
    #   pytablewriter
    #   tabledata
datasets==3.5.0
    # via
    #   distillkit (pyproject.toml)
    #   evaluate
    #   lm-eval
    #   trl
deepspeed==0.16.7
    # via distillkit (pyproject.toml)
dill==0.3.8
    # via
    #   datasets
    #   evaluate
    #   lm-eval
    #   multiprocess
distro==1.9.0
    # via openai
docker-pycreds==0.4.0
    # via wandb
einops==0.8.1
    # via deepspeed
evaluate==0.4.3
    # via
    #   distillkit (pyproject.toml)
    #   lm-eval
filelock==3.18.0
    # via
    #   datasets
    #   huggingface-hub
    #   torch
    #   transformers
fonttools==4.57.0
    # via matplotlib
frozenlist==1.6.0
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.12.0
    # via
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   torch
gitdb==4.0.12
    # via gitpython
gitpython==3.1.44
    # via wandb
h11==0.14.0
    # via httpcore
hf-transfer==0.1.9
    # via distillkit (pyproject.toml)
hjson==3.1.0
    # via deepspeed
httpcore==1.0.8
    # via httpx
httpx==0.28.1
    # via openai
huggingface-hub==0.30.2
    # via
    #   accelerate
    #   datasets
    #   evaluate
    #   peft
    #   tokenizers
    #   transformers
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
jinja2==3.1.6
    # via torch
jiter==0.9.0
    # via openai
joblib==1.4.2
    # via
    #   nltk
    #   scikit-learn
jsonlines==4.0.0
    # via lm-eval
kiwisolver==1.4.8
    # via matplotlib
lm-eval @ git+https://github.com/EleutherAI/lm-evaluation-harness.git@fc5019ead53c45119c522c62e8eea2daa837c56e
    # via distillkit (pyproject.toml)
lxml==5.4.0
    # via sacrebleu
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.2
    # via jinja2
matplotlib==3.10.1
    # via bert-score
mbstrdecoder==1.1.4
    # via
    #   dataproperty
    #   pytablewriter
    #   typepy
mdurl==0.1.2
    # via markdown-it-py
more-itertools==10.7.0
    # via lm-eval
mpmath==1.3.0
    # via sympy
msgpack==1.1.0
    # via deepspeed
multidict==6.4.3
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via
    #   datasets
    #   evaluate
networkx==3.4.2
    # via torch
ninja==1.11.1.4
    # via
    #   distillkit (pyproject.toml)
    #   deepspeed
nltk==3.9.1
    # via rouge-score
numexpr==2.10.2
    # via lm-eval
numpy==2.2.5
    # via
    #   accelerate
    #   bert-score
    #   bitsandbytes
    #   contourpy
    #   datasets
    #   deepspeed
    #   evaluate
    #   matplotlib
    #   numexpr
    #   pandas
    #   peft
    #   rouge-score
    #   sacrebleu
    #   scikit-learn
    #   scipy
    #   transformers
nvidia-cublas-cu12==12.4.5.8
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.4.127
    # via torch
nvidia-cuda-nvrtc-cu12==12.4.127
    # via torch
nvidia-cuda-runtime-cu12==12.4.127
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.2.1.3
    # via torch
nvidia-curand-cu12==10.3.5.147
    # via torch
nvidia-cusolver-cu12==11.6.1.9
    # via torch
nvidia-cusparse-cu12==12.3.1.170
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.6.2
    # via torch
nvidia-nccl-cu12==2.21.5
    # via torch
nvidia-nvjitlink-cu12==12.4.127
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvtx-cu12==12.4.127
    # via torch
openai==1.75.0
    # via distillkit (pyproject.toml)
packaging==25.0
    # via
    #   distillkit (pyproject.toml)
    #   accelerate
    #   bert-score
    #   datasets
    #   deepspeed
    #   evaluate
    #   huggingface-hub
    #   matplotlib
    #   peft
    #   transformers
    #   typepy
pandas==2.2.3
    # via
    #   bert-score
    #   datasets
    #   evaluate
pathvalidate==3.2.3
    # via pytablewriter
peft==0.15.2
    # via lm-eval
pillow==11.2.1
    # via matplotlib
platformdirs==4.3.7
    # via wandb
portalocker==3.1.1
    # via sacrebleu
propcache==0.3.1
    # via
    #   aiohttp
    #   yarl
protobuf==6.30.2
    # via wandb
psutil==7.0.0
    # via
    #   accelerate
    #   deepspeed
    #   peft
    #   wandb
py-cpuinfo==9.0.0
    # via deepspeed
pyarrow==19.0.1
    # via datasets
pybind11==2.13.6
    # via lm-eval
pydantic==2.11.3
    # via
    #   deepspeed
    #   openai
    #   wandb
pydantic-core==2.33.1
    # via pydantic
pygments==2.19.1
    # via rich
pyparsing==3.2.3
    # via matplotlib
pytablewriter==1.2.1
    # via lm-eval
python-dateutil==2.9.0.post0
    # via
    #   matplotlib
    #   pandas
    #   typepy
python-dotenv==1.1.0
    # via distillkit (pyproject.toml)
pytz==2025.2
    # via
    #   pandas
    #   typepy
pyyaml==6.0.2
    # via
    #   accelerate
    #   datasets
    #   huggingface-hub
    #   peft
    #   transformers
    #   wandb
regex==2024.11.6
    # via
    #   nltk
    #   sacrebleu
    #   transformers
requests==2.32.3
    # via
    #   bert-score
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   transformers
    #   wandb
rich==14.0.0
    # via trl
rouge-score==0.1.2
    # via
    #   distillkit (pyproject.toml)
    #   lm-eval
sacrebleu==2.5.1
    # via lm-eval
safetensors==0.5.3
    # via
    #   distillkit (pyproject.toml)
    #   accelerate
    #   peft
    #   transformers
scikit-learn==1.6.1
    # via lm-eval
scipy==1.15.2
    # via scikit-learn
sentry-sdk==2.26.1
    # via wandb
setproctitle==1.3.5
    # via wandb
setuptools==79.0.0
    # via
    #   distillkit (pyproject.toml)
    #   pytablewriter
    #   wandb
six==1.17.0
    # via
    #   docker-pycreds
    #   python-dateutil
    #   rouge-score
smmap==5.0.2
    # via gitdb
sniffio==1.3.1
    # via
    #   anyio
    #   openai
sqlitedict==2.1.0
    # via lm-eval
sympy==1.13.1
    # via torch
tabledata==1.3.4
    # via pytablewriter
tabulate==0.9.0
    # via sacrebleu
tcolorpy==0.1.7
    # via pytablewriter
threadpoolctl==3.6.0
    # via scikit-learn
tokenizers==0.21.1
    # via transformers
torch==2.6.0
    # via
    #   distillkit (pyproject.toml)
    #   accelerate
    #   bert-score
    #   bitsandbytes
    #   deepspeed
    #   lm-eval
    #   peft
tqdm==4.67.1
    # via
    #   bert-score
    #   datasets
    #   deepspeed
    #   evaluate
    #   huggingface-hub
    #   nltk
    #   openai
    #   peft
    #   tqdm-multiprocess
    #   transformers
tqdm-multiprocess==0.0.11
    # via lm-eval
transformers==4.51.3
    # via
    #   distillkit (pyproject.toml)
    #   bert-score
    #   lm-eval
    #   peft
    #   trl
triton==3.2.0
    # via torch
trl==0.16.1
    # via distillkit (pyproject.toml)
typepy==1.3.4
    # via
    #   dataproperty
    #   pytablewriter
    #   tabledata
typing-extensions==4.13.2
    # via
    #   anyio
    #   huggingface-hub
    #   openai
    #   pydantic
    #   pydantic-core
    #   torch
    #   typing-inspection
    #   wandb
typing-inspection==0.4.0
    # via pydantic
tzdata==2025.2
    # via pandas
urllib3==2.4.0
    # via
    #   requests
    #   sentry-sdk
wandb==0.19.10
    # via distillkit (pyproject.toml)
wheel==0.45.1
    # via distillkit (pyproject.toml)
word2number==1.1
    # via lm-eval
xxhash==3.5.0
    # via
    #   datasets
    #   evaluate
yarl==1.20.0
    # via aiohttp
zstandard==0.23.0
    # via lm-eval
